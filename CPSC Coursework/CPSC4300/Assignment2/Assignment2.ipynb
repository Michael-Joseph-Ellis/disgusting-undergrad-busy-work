{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30878faa",
   "metadata": {},
   "source": [
    "# Assignment 2 — Part 1: Linear Regression (HEAPO)\n",
    "\n",
    "This notebook part 1 fits the specified linear model:\n",
    "\n",
    "Consumption (kWh) = θ0 + θ1·Temperature_avg + θ2·Humidity_avg + θ3·Sunshine_Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55eb9a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_avg</th>\n",
       "      <th>humidity_avg</th>\n",
       "      <th>sunshine_hours</th>\n",
       "      <th>consumption_kWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-02</td>\n",
       "      <td>7.5</td>\n",
       "      <td>77.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>9.9</td>\n",
       "      <td>60.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>8.3</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>7.4</td>\n",
       "      <td>60.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>16.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temperature_avg  humidity_avg  sunshine_hours  consumption_kWh\n",
       "0 2019-03-02              7.5          77.1             1.0            18.33\n",
       "1 2019-03-03              9.9          60.3             6.3            15.03\n",
       "2 2019-03-04              8.3          57.4             0.5            16.69\n",
       "3 2019-03-05              7.4          60.2             6.7            29.52\n",
       "4 2019-03-06              6.0          68.2             2.7            16.81"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "DATA_PATH = 'data/heapo_cleaned_dataset.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0ac4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "θ0 (intercept): 27.4531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "theta_1 (Temp_avg)         -0.9496\n",
       "theta_2 (Humidity_avg)      0.0404\n",
       "theta_3 (Sunshine_Hours)   -0.5234\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features and label as specified in the prompt\n",
    "X = df[['temperature_avg', 'humidity_avg', 'sunshine_hours']]\n",
    "y = df['consumption_kWh']\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "coef_names = ['theta_1 (Temp_avg)', 'theta_2 (Humidity_avg)', 'theta_3 (Sunshine_Hours)']\n",
    "coefs = pd.Series(linreg.coef_, index=coef_names)\n",
    "intercept = linreg.intercept_\n",
    "\n",
    "print('θ0 (intercept):', round(intercept, 4))\n",
    "coefs.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6f930",
   "metadata": {},
   "source": [
    "### Interpretation (part a)\n",
    "- θ0 is the expected daily consumption when all features are 0.\n",
    "- θ1 is the change in kWh per 1°C increase in average temperature (holding others fixed).\n",
    "- θ2 is the change in kWh per +1% humidity.\n",
    "- θ3 is the change in kWh per additional sunshine hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2adc110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 96.6871 | R^2: 0.4342\n",
      "Test      MSE: 111.1049 | R^2: 0.2362\n"
     ]
    }
   ],
   "source": [
    "# Part (b): 90/10 split, train on 90%, evaluate on both\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=4300\n",
    ")\n",
    "\n",
    "linreg_split = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "train_pred = linreg_split.predict(X_train)\n",
    "test_pred = linreg_split.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mse_train = mean_squared_error(y_train, train_pred)\n",
    "r2_train = r2_score(y_train, train_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, test_pred)\n",
    "r2_test = r2_score(y_test, test_pred)\n",
    "\n",
    "print('Training MSE:', round(mse_train, 4), '| R^2:', round(r2_train, 4))\n",
    "print('Test      MSE:', round(mse_test, 4), '| R^2:', round(r2_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef95568",
   "metadata": {},
   "source": [
    "### Part (b)\n",
    "- Training: MSE = 96.6871, R² = 0.4342.\n",
    "- Test: MSE = 111.1049, R² = 0.2362.\n",
    "\n",
    "The model performs worse on the test set than on the training set (higher MSE, lower R²). This indicates overfitting and that a simple linear specification misses seasonal and household/behavioral factors; for time-ordered data, a chronological split is more appropriate than a random split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd02db",
   "metadata": {},
   "source": [
    "## Part 2: Logistic Regression (Pima Indians Diabetes)\n",
    "\n",
    "We will train Logistic Regression models with C ∈ {0.01, 0.1, 1, 10, 100} for both L1 and L2 penalties using a standardized feature pipeline, then report performance and coefficient behavior. this is part (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b50ebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.701954</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.784352</td>\n",
       "      <td>0.804074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.773616</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.838411</td>\n",
       "      <td>0.837037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.783388</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.840841</td>\n",
       "      <td>0.831296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.783388</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.840643</td>\n",
       "      <td>0.830926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.783388</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.840584</td>\n",
       "      <td>0.830741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.775244</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.833914</td>\n",
       "      <td>0.823519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.778502</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.840432</td>\n",
       "      <td>0.831296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.783388</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.840689</td>\n",
       "      <td>0.830926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l2</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.783388</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.840572</td>\n",
       "      <td>0.830741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.783388</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.840584</td>\n",
       "      <td>0.830741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  penalty       C  acc_train  acc_test  auc_train  auc_test\n",
       "0      l1    0.01   0.701954  0.714286   0.784352  0.804074\n",
       "1      l1    0.10   0.773616  0.792208   0.838411  0.837037\n",
       "2      l1    1.00   0.783388  0.779221   0.840841  0.831296\n",
       "3      l1   10.00   0.783388  0.779221   0.840643  0.830926\n",
       "4      l1  100.00   0.783388  0.779221   0.840584  0.830741\n",
       "5      l2    0.01   0.775244  0.746753   0.833914  0.823519\n",
       "6      l2    0.10   0.778502  0.785714   0.840432  0.831296\n",
       "7      l2    1.00   0.783388  0.779221   0.840689  0.830926\n",
       "8      l2   10.00   0.783388  0.779221   0.840572  0.830741\n",
       "9      l2  100.00   0.783388  0.779221   0.840584  0.830741"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Load\n",
    "PIMA_PATH = 'data/Pima_Indians_Diabetes.csv'\n",
    "pima = pd.read_csv(PIMA_PATH)\n",
    "\n",
    "X = pima.drop(columns=['Outcome'])\n",
    "y = pima['Outcome']\n",
    "\n",
    "# Train/test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=4300, stratify=y\n",
    ")\n",
    "\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "penalties = ['l1', 'l2']\n",
    "\n",
    "results = []\n",
    "coefs = {}\n",
    "\n",
    "for pen in penalties:\n",
    "    # 'liblinear' supports both L1 and L2 for binary classification\n",
    "    solver = 'liblinear'\n",
    "    for C in Cs:\n",
    "        pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', LogisticRegression(penalty=pen, C=C, solver=solver, max_iter=2000, random_state=4300))\n",
    "        ])\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        # Metrics\n",
    "        y_train_pred = pipe.predict(X_train)\n",
    "        y_test_pred = pipe.predict(X_test)\n",
    "        y_train_proba = pipe.predict_proba(X_train)[:, 1]\n",
    "        y_test_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        acc_train = accuracy_score(y_train, y_train_pred)\n",
    "        acc_test = accuracy_score(y_test, y_test_pred)\n",
    "        auc_train = roc_auc_score(y_train, y_train_proba)\n",
    "        auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "        results.append({'penalty': pen, 'C': C,\n",
    "                        'acc_train': acc_train, 'acc_test': acc_test,\n",
    "                        'auc_train': auc_train, 'auc_test': auc_test})\n",
    "\n",
    "        # Store coefficients (in original feature order)\n",
    "        clf = pipe.named_steps['clf']\n",
    "        coefs[(pen, C)] = pd.Series(clf.coef_.ravel(), index=X.columns)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=['penalty', 'C']).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9307e617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.773616</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.838411</td>\n",
       "      <td>0.837037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.778502</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.840432</td>\n",
       "      <td>0.831296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  penalty    C  acc_train  acc_test  auc_train  auc_test\n",
       "0      l1  0.1   0.773616  0.792208   0.838411  0.837037\n",
       "1      l2  0.1   0.778502  0.785714   0.840432  0.831296"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize best per penalty by test AUC, then by accuracy\n",
    "best_by_penalty = results_df.sort_values(['penalty','auc_test','acc_test'], ascending=[True, False, False])\\\n",
    "                              .groupby('penalty').head(1).reset_index(drop=True)\n",
    "best_by_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "094a7ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>nonzero</th>\n",
       "      <th>L1_norm</th>\n",
       "      <th>L2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223137</td>\n",
       "      <td>0.223137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>2.157978</td>\n",
       "      <td>1.106992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3.045049</td>\n",
       "      <td>1.412557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3.165268</td>\n",
       "      <td>1.454367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3.177538</td>\n",
       "      <td>1.458661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>1.438794</td>\n",
       "      <td>0.647056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>2.650539</td>\n",
       "      <td>1.225419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3.110030</td>\n",
       "      <td>1.428465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l2</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3.171722</td>\n",
       "      <td>1.455960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3.178121</td>\n",
       "      <td>1.458815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  penalty       C  nonzero   L1_norm   L2_norm\n",
       "0      l1    0.01        1  0.223137  0.223137\n",
       "1      l1    0.10        6  2.157978  1.106992\n",
       "2      l1    1.00        8  3.045049  1.412557\n",
       "3      l1   10.00        8  3.165268  1.454367\n",
       "4      l1  100.00        8  3.177538  1.458661\n",
       "5      l2    0.01        8  1.438794  0.647056\n",
       "6      l2    0.10        8  2.650539  1.225419\n",
       "7      l2    1.00        8  3.110030  1.428465\n",
       "8      l2   10.00        8  3.171722  1.455960\n",
       "9      l2  100.00        8  3.178121  1.458815"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show coefficient magnitudes vs C for L1 and L2 to illustrate sparsity/regularization strength\n",
    "coef_summary = []\n",
    "for pen in penalties:\n",
    "    for C in Cs:\n",
    "        s = coefs[(pen, C)].abs()\n",
    "        coef_summary.append({'penalty': pen, 'C': C,\n",
    "                             'nonzero': int((coefs[(pen, C)] != 0).sum()),\n",
    "                             'L1_norm': s.sum(), 'L2_norm': np.sqrt((coefs[(pen, C)]**2).sum())})\n",
    "coef_df = pd.DataFrame(coef_summary).sort_values(['penalty','C'])\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c92c46c",
   "metadata": {},
   "source": [
    "### Part b\n",
    "- Best L1 (by test AUC then accuracy): C = 0.1 with AUC ≈ 0.8370 and Accuracy ≈ 0.7922.\n",
    "- Best L2 (by test AUC then accuracy): C = 0.1 with AUC ≈ 0.8313 and Accuracy ≈ 0.7857.\n",
    "- As C increases (weaker regularization), both L1 and L2 generally increase coefficient magnitudes; L1 drives sparsity (fewer nonzero weights), L2 keeps all features with smaller magnitudes. Smaller C (stronger regularization) shrinks weights more and can improve generalization; overly large C can overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a09c65",
   "metadata": {},
   "source": [
    "## Part 3: Model Evaluation — Confusion and Cost\n",
    "We compute accuracy for M1 and M2 and total cost using the provided cost matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046d73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8), np.float64(0.9), 3910.0, 4255.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# These are the confusion matrices as given:\n",
    "# For both, assume rows are Actual [class=1, class=0], columns are Predicted [class=1, class=0]\n",
    "M1 = np.array([[150, 40],\n",
    "               [ 60,250]])\n",
    "M2 = np.array([[250, 45],\n",
    "               [  5,200]])\n",
    "\n",
    "# Accuracy\n",
    "acc_M1 = (M1[0,0] + M1[1,1]) / M1.sum()\n",
    "acc_M2 = (M2[0,0] + M2[1,1]) / M2.sum()\n",
    "\n",
    "# Cost matrix (rows: actual [pos, neg]; columns: predicted [pos, neg])\n",
    "# cost(actual=Positive, predicted=Positive) = -1\n",
    "# cost(actual=Positive, predicted=Negative) = 100\n",
    "# cost(actual=Negative, predicted=Positive) = 1\n",
    "# cost(actual=Negative, predicted=Negative) = 0\n",
    "C = np.array([[-1, 100],\n",
    "              [ 1,   0]])\n",
    "\n",
    "total_cost_M1 = float((M1 * C).sum())\n",
    "total_cost_M2 = float((M2 * C).sum())\n",
    "\n",
    "acc_M1, acc_M2, total_cost_M1, total_cost_M2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad74fe",
   "metadata": {},
   "source": [
    "### Part 3 — Direct answers\n",
    "(a) Accuracy\n",
    "- M1: 0.80 (400/500)\n",
    "- M2: 0.90 (450/500)\n",
    "\n",
    "(b) Total cost (using provided cost matrix)\n",
    "- M1: 3910\n",
    "- M2: 4255\n",
    "\n",
    "(c) Why higher accuracy but worse cost for M2?\n",
    "- M2 favors predicting positives, which raises accuracy but racks up many false positives. Given the cost matrix, those extra false positives and the remaining false negatives outweigh its gains, so total cost is higher.\n",
    "\n",
    "(d) When is accuracy misleading, and what would you look at instead?\n",
    "- Rare disease screening: A model can be “accurate” by calling almost everyone healthy. I’d care most about catching the sick people, so I’d focus on recall and a sensible balance with precision.\n",
    "- Spam filtering: A model can look accurate but flag a lot of legitimate emails as spam. Here I’d emphasize precision for the spam class to avoid false alarms, while keeping recall reasonable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
